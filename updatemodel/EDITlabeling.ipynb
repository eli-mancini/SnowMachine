{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN97jglVwxmMOU2wuGGj0BH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eli-mancini/SnowMachine/blob/main/updatemodel/EDITlabeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cR9OLRRDM65h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb86faf9-4286-4a66-f843-d44b8d451c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "written by Catherine M. Breen\n",
        "cbreen@uw.edu\n",
        "edited by Eli D. Mancini\n",
        "mpmancin@syr.edu\n",
        "\n",
        "Use of our keypoint detection model currently requires ~10 images per camera. We provide a labeling script below that when pointed\n",
        "at a camera directory (i.e., data > cam1 or data > cam2, etc), walks the user through labeling every 10th image and saves as labels.csv in a specified direrctory.\n",
        "\n",
        "We estimate it will take about 5 imgs/min or about 300 imgs per hour.\n",
        "\n",
        "x1,y1 = top\n",
        "x2,y2 = bottom\n",
        "\n",
        "The labels.csv file can then be directly pointed at train.py for fine-tuning. The user can then run predict.py to extract the snow depth.\n",
        "\n",
        "example run\n",
        "\n",
        "python src/labeling.py --datapath 'nontrained_data' --pole_length '304.8' --subset_to_label '2'\n",
        "\n",
        "'''\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import argparse\n",
        "import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "import datetime\n",
        "import IPython\n",
        "import numpy as np\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "include_colab_link = True\n",
        "\n",
        "  # Argument parser for command-line arguments:\n",
        "parser = argparse.ArgumentParser(description='Label snowpole images')\n",
        "parser.add_argument('--datapath', help='Path to image dir')\n",
        "parser.add_argument('--pole_length', help='Length of pole in cm', default = '100') ### assumes poles are 1 m / 100 cm tall\n",
        "parser.add_argument('--subset_to_label', help='# of images per camera to label', default = '10')\n",
        "args = parser.parse_args(['--datapath', '/content/drive/My Drive/starting_100', '--pole_length', '121.8', '--subset_to_label', '10'])\n",
        "\n",
        "def main():\n",
        "\n",
        "    ## labeling data\n",
        "  filename = []\n",
        "  PixelLengths = []\n",
        "  topX, topY, bottomX, bottomY = [],[],[],[]\n",
        "  creationTimes = []\n",
        "\n",
        "    ## customized data\n",
        "  pole_length = np.float64(args.pole_length)\n",
        "  subset_to_label = np.int16(args.subset_to_label)\n",
        "\n",
        "    ## some metadata data\n",
        "  cameraIDs= []\n",
        "  pole_lengths = [] ## tracks pole length\n",
        "  first_pole_pixel_length = []\n",
        "  conversions = []\n",
        "  widths, heights = [], []\n",
        "\n",
        "    ### loop to label every nth photo!\n",
        "i = 0\n",
        "dir_list = glob.glob(f\"{args.datapath}/**/*\")\n",
        "dir_list = sorted(dir_list)\n",
        "for j, file in enumerate(tqdm.tqdm(dir_list)):\n",
        "        cameraID = 'starting 100'\n",
        "        cameraIDs.append(cameraID)\n",
        "\n",
        "        ##whether to start counter over\n",
        "        if i % subset_to_label == 0:\n",
        "            img = cv2.imread(file)\n",
        "            width, height, channel = img.shape\n",
        "            ## assumes the cameras are stored in folder with their camera name\n",
        "            # EDIT: folder does not have camera names, edit has not been made yet but soon :)\n",
        "            plt.figure(figsize = (20,10))\n",
        "            plt.imshow(img)\n",
        "            plt.title('label top and then bottom', fontweight = \"bold\")\n",
        "            top, bottom = plt.ginput(2)\n",
        "            topX.append(top[0]), topY.append(top[1])\n",
        "            bottomX.append(bottom[0]), bottomY.append(bottom[1])\n",
        "            plt.close()\n",
        "\n",
        "            PixelLength = math.dist(top, bottom)\n",
        "            PixelLengths.append(PixelLength)\n",
        "\n",
        "            ## to get the pixel to centimeter conversion\n",
        "\n",
        "            if i == 0:\n",
        "                ## with the first photo, we will get some metadata\n",
        "                conversion = pole_length/PixelLength\n",
        "                ## and get metadata\n",
        "                first_pole_pixel_length.append(PixelLength)\n",
        "                conversions.append(conversion)\n",
        "                pole_lengths.append(pole_length)\n",
        "                heights.append(height), widths.append(width)\n",
        "\n",
        "            else: pass\n",
        "            filename.append(file.split('/')[-1])\n",
        "            creationTime = os.path.getctime(file)\n",
        "            dt_c = datetime.datetime.fromtimestamp(creationTime)\n",
        "            creationTimes.append(dt_c)\n",
        "        i+=1\n",
        "        print(i)\n",
        "\n",
        "        df = pd.DataFrame({'filename':filename, 'datetime':creationTimes, 'x1':topX,'y1':topY, 'x2':bottomX,\n",
        "                        'y2':bottomY, 'PixelLengths':PixelLengths})\n",
        "\n",
        "    ## simplified table for snow depth conversion later on\n",
        "        metadata = pd.DataFrame({'camera_id':pd.unique(cameraIDs), 'pole_length_cm':pole_lengths,\n",
        "                             'pole_length_px':(first_pole_pixel_length),\n",
        "                             'pixel_cm_conversion':pd.unique(conversions),'width':widths,'height':heights})\n",
        "\n",
        "        df.to_csv(f'{args.datapath}/labels.csv', index=False)\n",
        "        metadata.to_csv(f'{args.datapath}/pole_metadata.csv', index=False)\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "           main()\n"
      ]
    }
  ]
}