# -*- coding: utf-8 -*-
"""editlabeling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p-ijSD90cKD8y48WcAk0s-1R8DwCO158
"""

# -*- coding: utf-8 -*-
"""EDITlabeling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/eli-mancini/SnowMachine/blob/main/updatemodel/EDITlabeling.ipynb
"""

'''
written by Catherine M. Breen
cbreen@uw.edu
edited by Eli D. Mancini
mpmancin@syr.edu

Use of our keypoint detection model currently requires ~10 images per camera. We provide a labeling script below that when pointed
at a camera directory (i.e., data > cam1 or data > cam2, etc), walks the user through labeling every 10th image and saves as labels.csv in a specified direrctory.

We estimate it will take about 5 imgs/min or about 300 imgs per hour.

x1,y1 = top
x2,y2 = bottom

The labels.csv file can then be directly pointed at train.py for fine-tuning. The user can then run predict.py to extract the snow depth.

example run

python src/labeling.py --datapath 'nontrained_data' --pole_length '168' --subset_to_label '2'

'''

import cv2
!pip install -q google.colab
import google.colab
import matplotlib.pyplot as plt
import glob
import argparse
import tqdm
import math
import pandas as pd
import os
import datetime
import IPython
import numpy as np
import sys
from google.colab import drive
drive.mount('/content/drive')
include_colab_link = True

# Argument parser for command-line arguments:
parser = argparse.ArgumentParser(description='Labeling script for snow depth estimation.')
parser.add_argument('--datapath', type=str, help='Path to the directory containing images.')
parser.add_argument('--pole_length', type=int, default='168', help='Length of the pole in cm.')
parser.add_argument('--subset_to_label', type=int, default=5, help='Subset of images to label (e.g., every 2nd image).')
parser.add_argument('-lengths_file', type=str, default=None, help='path to csv file with lengths')
parser.set_defaults(datapath='/content/drive/MyDrive/starting100', pole_length='168', subset_to_label='5', lengths_file='/content/drive/MyDrive/updatelengths.csv')
args = parser.parse_args([])

def main():
  print("Entering main function")
    ## labeling data
  filename = []
  PixelLengths = []
  topX, topY, bottomX, bottomY = [],[],[],[]
  creationTimes = []

    ## customized data
  pole_length = np.float64(args.pole_length)
  subset_to_label = np.int16(args.subset_to_label)

    ## some metadata data
  pole_lengths = [] ## tracks pole length
  first_pole_pixel_length = []
  conversions = []
  widths, heights = [], []
  print("Main function starting ok")
    ### loop to label every nth photo!
  if args.lengths_file:
      lengths_df = pd.read_csv(args.lengths_file)
      lengths = 'lengths'
  else:
      lengths_df = pd.DataFrame(columns=['lengths', 'length'])
      lengths = 'lengths'
  first_image_processed = False
  i = 0
  dir_list = glob.glob(f'{args.datapath}/*')
  dir_list.sort()
  for j, file in tqdm.tqdm(enumerate(dir_list)):
          ##whether to start counter over
      if i % subset_to_label == 0:
              img = cv2.imread(file)
              if img is not None: #check if image was read successfully
                width, height, channel = img.shape
      if args.lengths_file:
              length_row = lengths_df[lengths_df[lengths]==file]
              if not length_row.empty:
                actual_Length = length_row['length'].values[0]
                plt.figure(figsize = (20,10))
                plt.imshow(img)
                plt.title('label top and then bottom', fontweight = "bold")

                # Get user input for top and bottom points
                try:
                    top, bottom = plt.ginput(2)
                    data.append({'filename':file,
                                 'datetime':datetime.datetime.fromtimestamp(os.path.getctime(file)).strftime('%Y-%m-%d %H:%M:%S'),
                                 'x1': top[0],
                                 'y1': top[1],
                                 'x2': bottom[0],
                                 'y2': bottom[1],
                                 'PixelLengths': (actual_Length/pole_length) * height
                              })
                except Exception as e:
                    print(f"Error getting input for image {file}: {e}")
                    topX.append(np.nan), topY.append(np.nan)
                    bottomX.append(np.nan), bottomY.append(np.nan)
                    # Handle the exception, e.g., skip the image or use default values
                    continue # This will skip to next image if error

                finally:
                    plt.close()
                PixelLength = (actual_Length/pole_length)*height
                PixelLengths.append(PixelLength)
                filename.append(file)
                creationTimes.append(datetime.datetime.fromtimestamp(os.path.getctime(file)).strftime('%Y-%m-%d %H:%M:%S'))
                cameraIDs.append(os.path.basename(os.path.dirname(file)))
  print("no loop issue")
              ## to get the pixel to centimeter conversion
  if i == 0 and not first_image_processed and len(PixelLengths):
                PixelLength = PixelLengths[0]
                conversion = pole_length/PixelLength
                    ## and get metadata
                first_pole_pixel_length.append(PixelLength)
                conversions.append(conversion)
                pole_lengths.append(pole_length)
                heights.append(height); widths.append(width)
                print("no conversion issue")

  else: pass
  i += 1
  print(i)

  df = pd.DataFrame({'filename': filename, 'datetime':creationTimes, 'x1':topX, 'y1':topY, 'x2':bottomX, 'y2':bottomY, 'PixelLengths':PixelLengths})
      ## simplified table for snow depth conversion later on
  metadata = pd.DataFrame({'pole_length_cm':pole_lengths,
                           'pole_length_px':(first_pole_pixel_length),
                          'pixel_cm_conversion':pd.unique(conversions),'width':widths,'height':heights})
  print("After creating DataFrame")
  df.to_csv(f'{args.datapath}/labels.csv', index=False)
  print("After saving to CSV")
  metadata.to_csv(f'{args.datapath}/pole_metadata.csv', index=False)

if __name__ == '__main__':
        main()

if os.path.exists(f'{args.datapath}/labels.csv'):
    print("labels.csv was created successfully!")
else:
    print("labels.csv was not created.")