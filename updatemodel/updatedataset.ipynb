{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF+UQYYBq9fu/RPiLbrNTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eli-mancini/SnowMachine/blob/main/updatedataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d0_pEHvvFi4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6daa0d6-0e06-4323-dcf2-a0930f5870c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: importlib in /usr/local/lib/python3.10/dist-packages (1.0.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sys (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sys\u001b[0m\u001b[31m\n",
            "\u001b[0mDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.10/dist-packages (1.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "written by: Catherine Breen\n",
        "June 2024\n",
        "\n",
        "Edited by Eli Mancini\n",
        "Decemver 2024\n",
        "\n",
        "Training script for users to fine tune model from Breen et. al 2024\n",
        "Please cite:\n",
        "\n",
        "Breen, C. M., Currier, W. R., Vuyovich, C., Miao, Z., & Prugh, L. R. (2024).\n",
        "Snow Depth Extraction From Time‚ÄêLapse Imagery Using a Keypoint Deep Learning Model.\n",
        "Water Resources Research, 60(7), e2023WR036682. https://doi.org/10.1029/2023WR036682\n",
        "'''\n",
        "\n",
        "import google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import torch\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install -q config\n",
        "import config\n",
        "from google.colab import files\n",
        "import io\n",
        "!pip install importlib\n",
        "import importlib\n",
        "!pip install -q sys\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "import update2config\n",
        "update2config.ROOT_PATH = '/content/drive/MyDrive/folders/starting_100'\n",
        "with open('/content/drive/MyDrive/update2config.py', 'r') as f:\n",
        "    notebook_content = f.read()\n",
        "    exec(notebook_content)\n",
        "importlib.reload(update2config)\n",
        "#import config_cpu as config ## for cpu training\n",
        "!pip install utils\n",
        "import utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageFile\n",
        "import albumentations as A\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to sample every third photo\n",
        "## Only used for experiments\n",
        "def sample_every_x(group, x):\n",
        "    indices = np.arange(len(group[1]))\n",
        "    every_x = len(group[1])//x\n",
        "    selected_indices = indices[2::every_x]\n",
        "    return group[1].iloc[selected_indices]\n",
        "\n",
        "def train_test_split(csv_path, image_path):\n",
        "\n",
        "    df_data = pd.read_csv(csv_path)\n",
        "    print(f'all rows in df_data {len(df_data.index)}')\n",
        "\n",
        "    training_samples = df_data.sample(frac=0.8, random_state=100) # same shuffle everytime\n",
        "    valid_samples = df_data[~df_data.index.isin(training_samples.index)]\n",
        "\n",
        "    ## check to make sure we only use images that exist\n",
        "    all_images = glob.glob(image_path + ('/**/*.JPG'))\n",
        "    filenames = [item.split('/')[-1] for item in all_images]\n",
        "    valid_samples = valid_samples[valid_samples['filename'].isin(filenames)].reset_index()\n",
        "    training_samples = training_samples[training_samples['filename'].isin(filenames)].reset_index()\n",
        "\n",
        "    # save labels to output folder\n",
        "    if not os.path.exists(f\"{update2config.OUTPUT_PATH}\"):\n",
        "            os.makedirs(f\"{update2config.OUTPUT_PATH}\", exist_ok=True)\n",
        "    training_samples.to_csv(f\"{update2config.OUTPUT_PATH}/training_samples.csv\")\n",
        "    valid_samples.to_csv(f\"{update2config.OUTPUT_PATH}/valid_samples.csv\")\n",
        "\n",
        "    print(f'# of examples we will now train on {len(training_samples)}, val on {len(valid_samples)}')\n",
        "\n",
        "    return training_samples, valid_samples"
      ],
      "metadata": {
        "id": "qRWWoaB5NdUk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class snowPoleDataset(Dataset):\n",
        "\n",
        "    def __init__(self, samples, path, aug): # split='train'):\n",
        "        self.data = samples\n",
        "        self.path = path\n",
        "        self.resize = 224\n",
        "\n",
        "        if aug == False:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(224, 224),\n",
        "                ], keypoint_params=A.KeypointParams(format='xy'))\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                A.ToFloat(max_value=1.0),\n",
        "                A.CropAndPad(px=75, p =1.0), ## final model is 50 pixels\n",
        "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.2, rotate_limit=20, p=0.5),\n",
        "                A.OneOf([\n",
        "                    A.RandomBrightnessContrast(p=0.5),\n",
        "                    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.5),\n",
        "                    A.ToGray(p=0.5)], p = 0.5),\n",
        "                A.Resize(224, 224),\n",
        "                ], keypoint_params=A.KeypointParams(format='xy'))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __filename__(self, index):\n",
        "\n",
        "        filename = self.data.iloc[index]['filename']\n",
        "        return filename\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        cameraID = self.data.iloc[index]['filename'].split('_')[0] ## may need to update this.\n",
        "        filename = self.data.iloc[index]['filename']\n",
        "\n",
        "        image = cv2.imread(f\"{self.path}/{cameraID}/{self.data.iloc[index]['filename']}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        orig_h, orig_w, channel = image.shape\n",
        "\n",
        "        # resize the image into `resize` defined above\n",
        "        image = cv2.resize(image, (self.resize, self.resize))\n",
        "        image = image / 255.0\n",
        "        # get the keypoints\n",
        "        keypoints = self.data.iloc[index][1:][['x1','y1','x2','y2']]  #[3:7]  ### change to x1 y1 x2 y2\n",
        "        keypoints = np.array(keypoints, dtype='float32')\n",
        "        # reshape the keypoints\n",
        "        keypoints = keypoints.reshape(-1, 2)\n",
        "\n",
        "        keypoints = keypoints * [self.resize / orig_w, self.resize / orig_h]\n",
        "\n",
        "        transformed = self.transform(image=image, keypoints=keypoints)\n",
        "        img_transformed = transformed['image']\n",
        "        keypoints = transformed['keypoints']\n",
        "\n",
        "        # viz training data\n",
        "\n",
        "        #utils.vis_keypoints(transformed['image'], transformed['keypoints'])\n",
        "        image = np.transpose(img_transformed, (2, 0, 1))\n",
        "\n",
        "        if len(keypoints) != 2:\n",
        "            utils.vis_keypoints(transformed['image'], transformed['keypoints'])\n",
        "\n",
        "        return {\n",
        "            'image': torch.tensor(image, dtype=torch.float),\n",
        "            'keypoints': torch.tensor(keypoints, dtype=torch.float),\n",
        "            'filename': filename\n",
        "        }"
      ],
      "metadata": {
        "id": "y8CGNugpMuZP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the training and validation data samples=\n",
        "directory_path = f\"{update2config.ROOT_PATH}\"\n",
        "\n",
        "labels = \"/content/drive/MyDrive/labels2.csv\"\n",
        "def my_train_test_split(labels,update2config): #removed .ROOT_PATH\n",
        "    df_data = pd.read_csv(labels)\n",
        "    print(f'all rows in df_data {len(df_data.index)}')\n",
        "\n",
        "    training_samples = df_data.sample(frac=0.8, random_state=100) # same shuffle everytime\n",
        "    valid_samples = df_data[~df_data.index.isin(training_samples.index)]\n",
        "    return training_samples, valid_samples\n",
        "\n",
        "training_samples, valid_samples = my_train_test_split(labels, update2config)\n",
        "\n",
        "# initialize the dataset - `snowPoleDataset()`\n",
        "train_data = snowPoleDataset(training_samples,\n",
        "                                 f\"{update2config.ROOT_PATH}\", aug = update2config.AUG)  ## we want all folders\n",
        "\n",
        "valid_data = snowPoleDataset(valid_samples,\n",
        "                                 f\"{update2config.ROOT_PATH}\", aug = False) # we always want the transform to be the normal transform\n",
        "camera_folder = directory_path\n",
        "all_images = glob.glob(os.path.join(camera_folder, '*.JPG'))\n",
        "filenames = [os.path.basename(item) for item in all_images]\n",
        "\n",
        "print(f\"Checking for images in: {update2config.ROOT_PATH}\")\n",
        "camera_folder = directory_path\n",
        "\\\n",
        "all_images = glob.glob(os.path.join(camera_folder, '*.JPG'))\n",
        "filenames = [os.path.basename(item) for item in all_images]\n",
        "# prepare data loaders\n",
        "train_loader = DataLoader(train_data,\n",
        "                          batch_size=update2config.BATCH_SIZE,\n",
        "                          shuffle=True, num_workers = 0)\n",
        "valid_loader = DataLoader(valid_data,\n",
        "                          batch_size=update2config.BATCH_SIZE,\n",
        "                          shuffle=False, num_workers = 0)\n",
        "\n",
        "print(f\"Training sample instances: {len(train_data)}\")\n",
        "print(f\"Validation sample instances: {len(valid_data)}\")\n",
        "\n",
        "if update2config.SHOW_DATASET_PLOT:\n",
        "    utils.dataset_keypoints_plot(train_data)\n",
        "    utils.dataset_keypoints_plot(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9HZXMKaM3GN",
        "outputId": "20b2a7a6-22d2-4a8b-dc1d-72bdc0862e88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all rows in df_data 6\n",
            "Checking for images in: /content/drive/MyDrive/starting_100\n",
            "Training sample instances: 5\n",
            "Validation sample instances: 1\n"
          ]
        }
      ]
    }
  ]
}
