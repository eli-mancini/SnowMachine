# -*- coding: utf-8 -*-
"""FigureTableCode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HTACEFM_SFSJpI1KQuOFAGKc0zmx4LLS
"""

import sys
sys.path.append('/usr/local/lib/python3.10/dist-packages/')
import google.colab
from google.colab import drive
drive.mount('/content/drive')
import sys
sys.path.append('/content/drive/MyDrive')
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
import pandas as pd
import sklearn
from sklearn.metrics import  mean_absolute_error
import numpy as np
from numpy import corrcoef
import matplotlib.pyplot as plt
import seaborn as sns
import scipy
from scipy import stats
import statsmodels.formula.api as sm
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import statsmodels.stats as stats

from google.colab import files
validation_training_loss_path = '/content/drive/MyDrive/newmodel/loss.png'
img = mpimg.imread(validation_training_loss_path)
plt.imshow(img)
plt.axis('off')
plt.title("Train Loss and Validation Loss during Model Training")
plt.show()
plt.savefig('trainvalid.jpg')
files.download('trainvalid.jpg')

"""Figure 1. Train loss and validation loss during model training. The updatemodel.py module generated a line graph showing how train loss and validation loss changed over the 20 epoch runs during the model training process. Validation loss is shown by the pink line, while train loss is shown by the yellow line.

The line graph in Figure 1 shows how train loss and validation loss changed over time during model training. Although both showed a general decrease over the twenty epoch runs, validation loss began to increase after ten epochs, showing fitting issues with the model. The gap between train loss and validation loss stayed somewhat large throughout the whole training. This gap that the model struggled to predict the snowdepths in the validation set and relied heavily on the training set.
"""

realvmodel_path= '/content/drive/MyDrive/realvmodel.csv'
realvmodel = pd.read_csv(realvmodel_path)

realvmodel['Residual_Error'] = realvmodel['SnowDepth_cm'] - realvmodel['Predicted_cm']
intrealvmodel = realvmodel.select_dtypes(include=np.number)
print(np.mean(intrealvmodel))

correlation_coefficient = realvmodel['SnowDepth_cm'].corr(realvmodel['Predicted_cm'])
r_squared = correlation_coefficient ** 2
print("R-squared:", r_squared)
print("Correlation Coefficient:", correlation_coefficient)

mae = mean_absolute_error(realvmodel['SnowDepth_cm'], realvmodel['Predicted_cm'])
print("Mean Absolute Error (MAE):", mae)

"""Table 1. Statistics table for the overall model, including mean residual error, R-squared value, correlation coefficient, and mean absolute error (MAE). All values were calculated based on differences between predicted and measured snowdepth (cm).

In order to judge the accuracy of the model, the Mean Residual Error, R2 value, Correlation Coefficient, and Mean Absolute Error (MAE) were calculated. The results of these calculations were put in Table 1 as seen below. Mean Residual Error was 6.07 cm, which means that on average the predicted values of snowdepth were 6.07cm less than the actual snowdepth. The R2 value was extremely low (0.11) and the correlation coefficient was -0.34. The R2 shows a weak relationship between predicted snowdepths and actual snowdepths. The slightly negative correlation coefficient implies an inverse relationship between predicted and actual snowdepths, furthering the evidence for an inaccurate model. The mean absolute error was around 11.35cm, which means that the average predicted snowdepth was not close at all to the actual snowdepth.


"""

realvmodel['SnowDepth_Bin_Range'] = pd.cut(realvmodel['SnowDepth_cm'], bins=bin_edges, labels=['0-3', '3-7', '7-9', '9-12', '12-25'])
sns.boxplot(x='SnowDepth_Bin_Range', y='Residual_Error', data=realvmodel)
plt.xlabel('Snow Depth Group (cm)')
plt.ylabel('Residual Error (cm)')
plt.title('Residual Error vs. Snow Depth Group (cm)')
plt.show()
meanbin = realvmodel.groupby('SnowDepth_Bin')['Residual_Error'].mean()
print(meanbin)
model = sm.ols(formula='Residual_Error ~ SnowDepth_Bin', data=realvmodel).fit()
anova_table = anova_lm(model, typ=2)
print(anova_table)
realvmodel['SnowDepth_Bin'] = pd.cut(realvmodel['SnowDepth_cm'], bins=bin_edges, labels=False)
plt.savefig('reserrorbin.png')
files.download('reserrorbin.png')

reserrorbinbrightness=sns.boxplot(x='SnowDepth_Bin', y='Residual_Error', hue='Brightness', data=realvmodel,
            palette={'Day': 'orange', 'Night': 'blue'}, dodge=True)
plt.savefig('reserrorbinbrightness.png')
files.download('reserrorbinbrightness.png')

"""Figure 2. Box and whisker plot of residual error (cm) based on snowdepth group and separated by lighting conditions. Snow depth groupings were assigned through creating bins for each group. Images taken during the day are in orange, while those taken at night are in blue.

To take a closer look at residual errors, a box and whisker plot of residual error based on snowdepth grouping and separated by whether the image was taken at day or night was constructed. This is visualized in Figure 2. Residual errors were similar between images taken during the daytime and nighttime for snowdepth groupings. However, residual errors were lowest for images with a snowdepth between 3-7cm and 7-9cm. On the other hand, images with snowdepths of 0-3cm had the largest range of residual errors. Images with snowdepths of 9-12 and 12-25cm also had larger residual errors, but with less of a range than that of the 0-3cm images.

"""

